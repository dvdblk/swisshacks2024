{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemma NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dvdblk/dev/swisshacks2024/venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:00<00:00, 16.82it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(load_in_4bit=True)\n",
    "\n",
    "# Use Gemma-2-9B\n",
    "model_name = \"google/gemma-2-9B-it\"\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    #quantization_config=bnb_config,\n",
    "    device_map=\"cpu\",\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    token=os.getenv(\"HF_TOKEN\"),\n",
    ").bfloat16()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the input text\n",
    "input_text = \"\"\n",
    "\n",
    "# Encode the input text\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #model(input_ids=input_ids, return_dict=True, output_hidden_states=True)\n",
    "\n",
    "# # Generate text\n",
    "# output = model.generate(\n",
    "#     input_ids,\n",
    "#     max_length=10,\n",
    "#     temperature=0.0,\n",
    "#     #num_return_sequences=5,\n",
    "#     pad_token_id=tokenizer.eos_token_id\n",
    "# )\n",
    "\n",
    "# print(\"Token ids:\", output)\n",
    "\n",
    "# # decode the output and print it\n",
    "# print(tokenizer.decode(output[0], skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load 'client_features.csv' from the data folder\n",
    "with open(os.getenv(\"DATA_PATH\") + \"/client_features.csv\", \"r\") as f:\n",
    "    client_features_string = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "INSTRUCTIONS = \"\"\"You are an AI assistant that analyzes transcripts and compares them to a database of people. ALWAYS provide your responses in the following JSON format:\n",
    "{\n",
    "\"is_factually_correct\": <yes|no>,\n",
    "\"reasoning\": <Your short step-by-step reasoning here>\n",
    "}\n",
    "\n",
    "Ensure your response can be parsed as valid JSON (it has to start and end with curly braces and nothing else). Do not include any text outside of this JSON structure in your response.\"\"\"\n",
    "\n",
    "\n",
    "def check_transcript(transcript, model, tokenizer):\n",
    "    chat = [\n",
    "        {\"role\": \"user\", \"content\": f\"\"\"{INSTRUCTIONS}\n",
    "        Here is a database of people:\n",
    "        {client_features_string}\n",
    "\n",
    "        And here is a transcript:\n",
    "        \"{transcript}\"\n",
    "\n",
    "        Is this transcript factually correct according to the database? Analyze the data and provide your response in the requested JSON format.\n",
    "        \"\"\"}\n",
    "    ]\n",
    "    chat2 = [\n",
    "        {\"role\": \"user\", \"content\": \"hi\"}\n",
    "    ]\n",
    "    prompt = tokenizer.apply_chat_template(chat, tokenize=False, add_generation_prompt=True)\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(\"cpu\")\n",
    "    outputs = model.generate(**inputs, max_new_tokens=500)\n",
    "    #response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    response = tokenizer.decode(outputs[0][inputs[\"input_ids\"].shape[1]:], skip_special_tokens=True)\n",
    "\n",
    "    try:\n",
    "        result = json.loads(response)\n",
    "        return result\n",
    "    except json.JSONDecodeError:\n",
    "        return {\"error\": \"Failed to parse JSON\", \"raw_output\": response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load transcripts.csv file into a dictionary\n",
    "import csv\n",
    "\n",
    "transcripts = {}\n",
    "\n",
    "with open(os.getenv(\"DATA_PATH\") + \"/transcriptions.csv\", \"r\") as file:\n",
    "    reader = csv.DictReader(file)\n",
    "    for row in reader:\n",
    "        transcripts[row[\"Audio File\"]] = row[\"Transcription\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'is_factually_correct': 'no', 'reasoning': 'The provided Social Security Number 7667-587-79988 does not match any record in the database. Additionally, the name provided, Noya Chimurman, is not present in the database.'}\n"
     ]
    }
   ],
   "source": [
    "tx = list(transcripts.values())[0]\n",
    "print(check_transcript(tx, model, tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
